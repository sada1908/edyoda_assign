{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0e07c2f1",
      "metadata": {
        "id": "0e07c2f1"
      },
      "source": [
        "# ğŸ¤– Assignment 2: Deep Learning vs. Traditional Machine Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "800d69a7",
      "metadata": {
        "id": "800d69a7"
      },
      "source": [
        "In this notebook, we explore the differences between traditional Machine Learning (ML) and Deep Learning (DL), specifically in the context of image recognition using the MNIST handwritten digit dataset.\n",
        "\n",
        "---\n",
        "\n",
        "### **Objectives**\n",
        "- Understand when to use DL over ML\n",
        "- Implement both ML and DL approaches\n",
        "- Compare performance metrics and explain why DL excels for this task\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2181ed50",
      "metadata": {
        "id": "2181ed50"
      },
      "source": [
        "## ğŸ“Š Traditional ML vs Deep Learning\n",
        "\n",
        "| Aspect                    | Traditional ML                      | Deep Learning                            |\n",
        "|--------------------------|-------------------------------------|------------------------------------------|\n",
        "| **Feature Engineering**   | Manual, requires domain expertise   | Automatic (learns features from data)    |\n",
        "| **Data Requirements**     | Works with small datasets           | Requires large datasets                  |\n",
        "| **Interpretability**      | Easier to interpret                 | Harder to interpret (black box)          |\n",
        "| **Computation**           | Light to moderate                   | High, requires GPUs                      |\n",
        "| **Flexibility (e.g., images)** | Limited for unstructured data    | Very strong for unstructured data (e.g., images, audio) |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f0ae16b",
      "metadata": {
        "id": "5f0ae16b"
      },
      "source": [
        "## ğŸ“¥ Load and Prepare MNIST Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "6931aa73",
      "metadata": {
        "id": "6931aa73"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load MNIST data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalize data\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# Flatten for ML\n",
        "X_train_flat = X_train.reshape(-1, 28*28)\n",
        "X_test_flat = X_test.reshape(-1, 28*28)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWdGbWWorwpw",
        "outputId": "e56c1391-da36-45fc-d6dd-f34229f2206e"
      },
      "id": "qWdGbWWorwpw",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c92a84f5",
      "metadata": {
        "id": "c92a84f5"
      },
      "source": [
        "## ğŸ§  Traditional ML: Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ea4cabdd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ea4cabdd",
        "outputId": "662c8e36-ca6e-4745-ac73-4274311505a7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9259"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Use only a subset for faster training (optional)\n",
        "ml_model = LogisticRegression(max_iter=1000)\n",
        "ml_model.fit(X_train_flat, y_train)\n",
        "\n",
        "ml_preds = ml_model.predict(X_test_flat)\n",
        "ml_accuracy = accuracy_score(y_test, ml_preds)\n",
        "ml_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8402e01",
      "metadata": {
        "id": "e8402e01"
      },
      "source": [
        "## ğŸ§  Deep Learning: Neural Network (Keras)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "069f5dde",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "069f5dde",
        "outputId": "551d6c48-7baa-4d60-f2dd-a5cd54ed8588"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.8781 - loss: 0.4312\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9640 - loss: 0.1225\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9763 - loss: 0.0773\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9820 - loss: 0.0591\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9864 - loss: 0.0439\n",
            "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9702 - loss: 0.0955\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.975600004196167"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Convert labels to categorical for DL\n",
        "y_train_cat = to_categorical(y_train, 10)\n",
        "y_test_cat = to_categorical(y_test, 10)\n",
        "\n",
        "# Define simple neural network\n",
        "dl_model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile and train\n",
        "dl_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "dl_model.fit(X_train, y_train_cat, epochs=5, batch_size=32, verbose=1)\n",
        "\n",
        "# Evaluate\n",
        "dl_loss, dl_accuracy = dl_model.evaluate(X_test, y_test_cat)\n",
        "dl_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90aca6eb",
      "metadata": {
        "id": "90aca6eb"
      },
      "source": [
        "## ğŸ“ˆ Results & Analysis\n",
        "\n",
        "- **Traditional ML Accuracy**: 92.6 %\n",
        "- **Deep Learning Accuracy**:  97.6 %\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ’¬ Why Deep Learning Performs Better\n",
        "\n",
        "- The DL model automatically **extracts pixel-level patterns** without needing manual feature design.\n",
        "- It can detect **curves, edges, and textures** important for digit recognition.\n",
        "- Traditional ML (like Logistic Regression) treats each pixel as a flat input and doesnâ€™t learn spatial hierarchies.\n",
        "- DL also benefits from GPU acceleration and deeper architectures as data size increases.\n",
        "\n",
        "---\n",
        "\n",
        "### âœ… Conclusion\n",
        "\n",
        "For image-based problems like MNIST, **deep learning outperforms traditional ML** due to its strength in feature extraction and hierarchical learning. However, for structured/tabular data, ML may still be more efficient and interpretable.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}